{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n    利用tanh(x)对符号函数sign(x)的近似：\\n    1）讨论近似后，公式（1）的凹凸性；\\n    2）分别利用随机梯度，最小批次随机梯度和梯度下降对（1）近似后进行优化，并观测优化过程与结果的关系。\\n'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 作业3：感知机（上）\n",
    "'''\n",
    "    利用tanh(x)对符号函数sign(x)的近似：\n",
    "    讨论近似后，公式（1）的凹凸性\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "【感知机】\n",
    "给定训练样本集$\\begin{aligened}D = {(x_{i}, y_{i})}, i=1, ..., N\\end{aligened}$。 一个自然的想法是让被正确\n",
    "分类样本的数量最大化。被正确分类样本的数量可以被表示为以下损失：\n",
    "\n",
    "$\\begin{aligened}L(w, b) = \\sum_{i=1}^{N}sign(g(x_{i};w,b)) y_{i}\\end{aligened}$  （1）\n",
    "\n",
    "其中，函数$\\begin{aligened}g(x_{i};w,b)\\end{aligened}$表示$\\begin{aligened}x\\end{aligened}$为输入，而$\\begin{aligened}w\\end{aligened}$和$\\begin{aligened}b\\end{aligened}$是参数。当$\\begin{aligened}x_{i}\\end{aligened}$被正确分类，那么\n",
    "$\\begin{aligened}sign(g(x_{i};w,b)) y_{i}=1\\end{aligened}$；当x被错误分类，那么$\\begin{aligened}sign(g(x_{i};w,b)) y_{i}=-1\\end{aligened}$。最\n",
    "大化损失函数就可以找到最优参数$\\begin{aligened}w\\end{aligened}$和$\\begin{aligened}b\\end{aligened}$。$\\begin{aligened}y=sign(x)\\end{aligened}$是不可导函数，我们拟\n",
    "利用$\\begin{aligened}tanh(x)\\end{aligened}$函数对$\\begin{aligened}sign(x)\\end{aligened}$进行近似：\n",
    "\n",
    "$\\begin{aligened}y=tanh(kx)\\end{aligened}$ （2）\n",
    "\n",
    "其中， $\\begin{aligened}k(k > 0)\\end{aligened}$参数控制函数$\\begin{aligened}tanh(kx)\\end{aligened}$的形状， $\\begin{aligened}k\\end{aligened}$越大$\\begin{aligened}tanh(kx)\\end{aligened}$就越接近$\\begin{aligened}sign(x)\\end{aligened}$。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 导库\n",
    "import sympy as sp\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 定义tanh函数和sign函数（不允许用np.tanh或np.sign）\n",
    "# tanh函数\n",
    "def tanh(x):\n",
    "    num = np.exp(x) - np.exp(-x)\n",
    "    den = np.exp(x) + np.exp(-x)\n",
    "    return num / den\n",
    "\n",
    "# sign函数\n",
    "def sign(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    elif x < 0:\n",
    "        return -1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "def loss_function(x, y, w, b, k=1, func='tanh'):\n",
    "    g_value = np.dot(w.T, x) + b\n",
    "    func_result = np.zeros(len(g_value))\n",
    "    # 判断函数类型（sign还是tanh）\n",
    "    if func == 'sign':\n",
    "        func_result = sign(g_value)\n",
    "    elif func == 'tanh':\n",
    "        func_result = tanh(k * g_value)\n",
    "    classifier = np.dot(func_result.T, y)\n",
    "    loss = np.sum(classifier)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 计算梯度\n",
    "def gradient(x, y, w, b, k):\n",
    "    gradient_w = np.zeros_like(w)\n",
    "    gradient_b = np.zeros_like(b)\n",
    "    for i in range(200):\n",
    "        prediction = tanh(np.dot(w, k * x[i]) + b)\n",
    "        judge = prediction * y[i]\n",
    "        if judge <= 0:\n",
    "            gradient_w += x[i] * (1 / np.cosh(np.dot(w, x[i]) + b) ** 2) * y[i]\n",
    "            gradient_b += (1 / np.cosh(np.dot(w, x[i]) + b) ** 2) * y[i]\n",
    "    return gradient_w, gradient_b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 函数凹凸性判断\n",
    "# 计算损失函数的海森矩阵并打印其特征值（关于x和y的函数）\n",
    "# 通过约分法、代值法等判断其正定性以判断函数凹凸性（若海森矩阵半正定，则函数为凸函数；反之凹函数）\n",
    "def judge_convexity_and_concavity(w_value, b_value, k_value):\n",
    "    x, y, w, b, k = sp.symbols('x y w b k')\n",
    "    func = sp.tanh(k * (w * x ++ b)) * y\n",
    "    first_derivative_x = sp.diff(func, x)\n",
    "    first_derivative_y = sp.diff(func, y)\n",
    "    second_derivate_x_x = sp.diff(first_derivative_x, x).evalf(subs ={'w': w_value, 'k': k_value})\n",
    "    second_derivate_x_y = sp.diff(first_derivative_x, y).evalf(subs ={'w': w_value, 'k': k_value})\n",
    "    second_derivate_y_y = sp.diff(first_derivative_y, y).evalf(subs ={'w': w_value, 'k': k_value})\n",
    "    second_derivate_y_x = sp.diff(first_derivative_y, x).evalf(subs ={'w': w_value, 'k': k_value})\n",
    "    hessian_matrix = sp.Matrix([[second_derivate_x_x, second_derivate_x_y],\n",
    "                               [second_derivate_y_x, second_derivate_y_y]])\n",
    "    eigenvalues = hessian_matrix.eigenvals()\n",
    "    print('When w value is {0}, k value is {1}, \\n'\n",
    "          'the eigenvalue of the Hessian matrix of the function is :\\n'\n",
    "          '{2}\\n'.format(w_value, k_value, eigenvalues.keys()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When w value is 10, k value is 10, \n",
      "the eigenvalue of the Hessian matrix of the function is :\n",
      "dict_keys([-10000.0*y*tanh(10*b + 100*x)/cosh(10*b + 100*x)**2 - 10000.0*sqrt(y**2*tanh(10*b + 100*x)**2 + 0.0001)/cosh(10*b + 100*x)**2, -10000.0*y*tanh(10*b + 100*x)/cosh(10*b + 100*x)**2 + 10000.0*sqrt(y**2*tanh(10*b + 100*x)**2 + 0.0001)/cosh(10*b + 100*x)**2])\n",
      "\n",
      "When w value is 10, k value is 100, \n",
      "the eigenvalue of the Hessian matrix of the function is :\n",
      "dict_keys([-1000000.0*y*tanh(100*b + 1000*x)/cosh(100*b + 1000*x)**2 - 1000000.0*sqrt(y**2*tanh(100*b + 1000*x)**2 + 1.0e-6)/cosh(100*b + 1000*x)**2, -1000000.0*y*tanh(100*b + 1000*x)/cosh(100*b + 1000*x)**2 + 1000000.0*sqrt(y**2*tanh(100*b + 1000*x)**2 + 1.0e-6)/cosh(100*b + 1000*x)**2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 判断凹凸性\n",
    "judge_convexity_and_concavity(w_value=10, b_value=1, k_value=10)\n",
    "judge_convexity_and_concavity(w_value=10, b_value=1, k_value=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
